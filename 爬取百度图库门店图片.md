### 爬取百度图库门店图片

我弄这个的背景是参加下面这个不出名的比赛来锻炼一下自己：

DC大数据竞赛——门店行业自动分类竞赛

<img src="https://img-blog.csdnimg.cn/f46a79cc438b4079aef60ef4f0b49140.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Z2Z6Z2ZX2ppbmdqaW5n,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom: 33%;" />

赛题的任务是：对给定的门店图片进行**分类**，门店种类一共分为四类：**餐饮、商店、生活服务、其他**。

 赛题官网给的数据集长这样：

<img src="https://img-blog.csdnimg.cn/8f1e4fdaa705430aba9a7baf177611aa.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Z2Z6Z2ZX2ppbmdqaW5n,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom: 33%;" />

**爬图片的动机：**

因为训练的模型出现了过拟合，并且比赛给的数据集很少，通过增加样本量来提升模型性能。原trainset中餐饮:775张、生活服务：748张、商店：618张、其他：112张，共2283张。由于没有现成的数据集，所以就想到爬取图片，补充数据集。



**数据爬取：**

在百度图库爬取的图片。

百度图片是动态加载的，每次加载30张

用xpath定位解析的方法不适用，百度图库有反爬机制，且它是动态加载，xpath只能定位静态html页面的元素。

将查询关键字和动态加载的页面id作为参数拼接到url中的键值对中，然后发送request请求，返回一个页面（包含30张图片）对应的json数据，解析json数据，获取图片地址，然后给图片地址发送的request并保存图片（以二进制的形式写文件）。



**数据清洗**：人工剔除爬取到的数据中的很多乱七八糟的图片，并打标签（将图片分类）[餐饮/生活服务/商店/其他]。

**清洗后的数据量：**每类400多张，一共1200张有效数据。

#### 下面是爬图片的代码

```python
import requests
import os
import urllib


class Spider_baidu_image():
    def __init__(self):
        self.url = 'http://image.baidu.com/search/acjson?'
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.\
            3497.81 Safari/537.36'}
        self.headers_image = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.\
            3497.81 Safari/537.36',
            'Referer': 'http://image.baidu.com/search/index?tn=baiduimage&ipn=r&ct=201326592&cl=2&lm=-1&st=-1&fm=result&fr=&sf=1&fmq=1557124645631_R&pv=&ic=&nc=1&z=&hd=1&latest=0&copyright=0&se=1&showtab=0&fb=0&width=&height=&face=0&istype=2&ie=utf-8&sid=&word=%E8%83%A1%E6%AD%8C'}
        # self.keyword = '刘亦菲壁纸'
        self.keyword = input("请输入搜索图片关键字:")
        self.paginator = int(input("请输入搜索页数，每页30张图片："))
        # self.paginator = 50
        # print(type(self.keyword),self.paginator)
        # exit()

    def get_param(self):
        """
        获取url请求的参数，存入列表并返回
        :return:
        """
        keyword = urllib.parse.quote(self.keyword)
        params = []
        for i in range(0, self.paginator):
            params.append('tn=resultjson_com&ipn=rj&ct=201326592&is=&fp=result&queryWord={}&cl=2&lm=-1&ie=utf-8&oe=utf-8&adpicid=&st=-1&z=&ic=&hd=1&latest=0&copyright=0&word={}&s=&se=&tab=&width=&height=&face=0&istype=2&qc=&nc=1&fr=&expermode=&force=&cg=star&pn={}&rn=30&gsm=1e&1623392917991='
                .format(keyword, keyword, 30 * i))
        return params

    def get_urls(self, params):
        """
        由url参数返回各个url拼接后的响应，存入列表并返回
        :return:
        """
        urls = []
        for i in params:
            urls.append(self.url + i)
        return urls

    def get_image_url(self, urls):
        image_url = []
        for url in urls:
            json_data = requests.get(url, headers=self.headers).json()
            json_data = json_data.get('data')
            for i in json_data:
                if i:
                    image_url.append(i.get('thumbURL'))
        return image_url

    def get_image(self, image_url):
        """
        根据图片url，在本地目录下新建一个以搜索关键字命名的文件夹，然后将每一个图片存入。
        :param image_url:
        :return:
        """
        cwd = os.getcwd()
        file_name = os.path.join(cwd, self.keyword)
        if not os.path.exists(self.keyword):
            os.mkdir(file_name)
        for index, url in enumerate(image_url, start=1):
            with open(file_name + '\\{}.jpg'.format(index), 'wb') as f:
                f.write(requests.get(url, headers=self.headers_image).content)
            if index != 0 and index % 30 == 0:
                print('{}第{}页下载完成'.format(self.keyword, index / 30))

    def __call__(self, *args, **kwargs):
        params = self.get_param()
        urls = self.get_urls(params)
        image_url = self.get_image_url(urls)
        self.get_image(image_url)


if __name__ == '__main__':
    spider = Spider_baidu_image()
    spider()

```





